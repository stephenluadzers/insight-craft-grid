/**
 * Business-Ready Workflow Export System
 * Exports FlowFuse workflows to multiple platforms and formats
 */

import { WorkflowNodeData } from "@/types/workflow";
import JSZip from "jszip";

export type ExportPlatform = 
  | 'n8n'
  | 'make'
  | 'zapier'
  | 'python'
  | 'typescript'
  | 'docker'
  | 'github-actions'
  | 'supabase-function'
  | 'standalone';

export interface GuardrailMetadata {
  explanations?: any[];
  complianceStandards?: string[];
  riskScore?: number;
  policyAnalysis?: {
    detectedDataTypes?: string[];
    complianceStandards?: string[];
    potentialRisks?: Array<{ risk: string; severity: string; mitigation: string }>;
    recommendedGuardrails?: Array<{ type: string; reason: string; implementation: string }>;
  };
}

export interface ExportOptions {
  platform: ExportPlatform;
  includeCredentials?: boolean;
  includeDocs?: boolean;
  includeTests?: boolean;
  deploymentTarget?: 'cloud' | 'self-hosted' | 'hybrid';
  guardrailMetadata?: GuardrailMetadata;
}

// === n8n Export ===
function generateN8NWorkflow(nodes: WorkflowNodeData[], workflowName: string) {
  return {
    name: workflowName,
    nodes: nodes.map((node, index) => ({
      parameters: node.config || {},
      name: node.title,
      type: mapToN8NNodeType(node.type),
      typeVersion: 1,
      position: [node.x, node.y],
      id: node.id,
      ...(index > 0 && {
        webhookId: undefined,
      }),
    })),
    connections: nodes.slice(0, -1).reduce((acc, node, index) => {
      acc[node.id] = {
        main: [[{ node: nodes[index + 1].id, type: 'main', index: 0 }]]
      };
      return acc;
    }, {} as any),
    active: false,
    settings: {},
    versionId: "1",
  };
}

function mapToN8NNodeType(type: string): string {
  const typeMap: Record<string, string> = {
    trigger: 'n8n-nodes-base.webhook',
    action: 'n8n-nodes-base.httpRequest',
    condition: 'n8n-nodes-base.if',
    data: 'n8n-nodes-base.set',
    ai: 'n8n-nodes-base.openAi',
  };
  return typeMap[type] || 'n8n-nodes-base.noOp';
}

// === Make.com Export ===
function generateMakeScenario(nodes: WorkflowNodeData[], workflowName: string) {
  return {
    name: workflowName,
    flow: nodes.map((node, index) => ({
      id: index + 1,
      module: mapToMakeModule(node.type),
      version: 1,
      parameters: node.config || {},
      mapper: index > 0 ? { [index]: 1 } : {},
      metadata: {
        designer: {
          x: node.x,
          y: node.y
        },
        restore: {},
        expect: []
      }
    })),
    metadata: {
      version: 1,
      scenario: {
        roundtrips: 1,
        maxErrors: 3,
        autoCommit: true,
        autoCommitTriggerLast: true,
        sequential: false,
        confidential: false,
        dataloss: false,
        dlq: false
      },
      designer: {
        orphans: []
      }
    }
  };
}

function mapToMakeModule(type: string): string {
  const moduleMap: Record<string, string> = {
    trigger: 'gateway:CustomWebhook',
    action: 'http:ActionSendData',
    condition: 'builtin:BasicRouter',
    data: 'util:SetVariable2',
    ai: 'openai:CreateCompletion',
  };
  return moduleMap[type] || 'util:NoOp';
}

// === Python Standalone Export ===
function generatePythonScript(nodes: WorkflowNodeData[], workflowName: string) {
  return `#!/usr/bin/env python3
"""
${workflowName} - FlowFuse Workflow
Auto-generated Python implementation
"""

import os
import json
import requests
from typing import Dict, Any, Optional
from dataclasses import dataclass
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class WorkflowResult:
    success: bool
    data: Optional[Dict[str, Any]] = None
    error: Optional[str] = None

class ${workflowName.replace(/[^a-zA-Z0-9]/g, '')}Workflow:
    """Automated workflow generated from FlowFuse"""
    
    def __init__(self):
        # Load credentials from environment
        self.config = {
            'openai_api_key': os.getenv('OPENAI_API_KEY'),
            'webhook_url': os.getenv('WEBHOOK_URL'),
            # Add other credentials as needed
        }
    
${nodes.map((node, idx) => generatePythonNodeFunction(node, idx)).join('\n\n')}
    
    def execute(self, input_data: Dict[str, Any]) -> WorkflowResult:
        """Execute the complete workflow"""
        logger.info("Starting workflow execution")
        context = {'input': input_data}
        
        try:
${nodes.map((node, idx) => `            # Step ${idx + 1}: ${node.title}
            result = self.${sanitizePythonName(node.title)}(context)
            if not result.success:
                return result
            context['step_${idx + 1}'] = result.data`).join('\n\n')}
            
            logger.info("Workflow completed successfully")
            return WorkflowResult(success=True, data=context)
            
        except Exception as e:
            logger.error(f"Workflow failed: {str(e)}")
            return WorkflowResult(success=False, error=str(e))

if __name__ == "__main__":
    # Example usage
    workflow = ${workflowName.replace(/[^a-zA-Z0-9]/g, '')}Workflow()
    
    # Sample input data
    input_data = {
        "sample": "data"
    }
    
    result = workflow.execute(input_data)
    
    if result.success:
        print("‚úì Workflow completed successfully")
        print(json.dumps(result.data, indent=2))
    else:
        print(f"‚úó Workflow failed: {result.error}")
        exit(1)
`;
}

function generatePythonNodeFunction(node: WorkflowNodeData, index: number): string {
  const funcName = sanitizePythonName(node.title);
  
  switch (node.type) {
    case 'trigger':
      return `    def ${funcName}(self, context: Dict[str, Any]) -> WorkflowResult:
        """${node.description}"""
        logger.info("Trigger: ${node.title}")
        # Webhook trigger - data comes from input
        return WorkflowResult(success=True, data=context.get('input'))`;
    
    case 'ai':
      return `    def ${funcName}(self, context: Dict[str, Any]) -> WorkflowResult:
        """${node.description}"""
        logger.info("AI Processing: ${node.title}")
        
        if not self.config.get('openai_api_key'):
            return WorkflowResult(success=False, error="OpenAI API key not configured")
        
        try:
            response = requests.post(
                'https://api.openai.com/v1/chat/completions',
                headers={'Authorization': f"Bearer {self.config['openai_api_key']}"},
                json={
                    'model': 'gpt-4',
                    'messages': [
                        {'role': 'system', 'content': 'You are a helpful assistant'},
                        {'role': 'user', 'content': str(context)}
                    ]
                }
            )
            response.raise_for_status()
            result = response.json()['choices'][0]['message']['content']
            return WorkflowResult(success=True, data={'ai_response': result})
        except Exception as e:
            return WorkflowResult(success=False, error=f"AI processing failed: {str(e)}")`;
    
    case 'action':
      return `    def ${funcName}(self, context: Dict[str, Any]) -> WorkflowResult:
        """${node.description}"""
        logger.info("Action: ${node.title}")
        
        try:
            # Perform action (customize based on your needs)
            response = requests.post(
                self.config.get('webhook_url', 'https://example.com/webhook'),
                json=context,
                timeout=30
            )
            response.raise_for_status()
            return WorkflowResult(success=True, data=response.json())
        except Exception as e:
            return WorkflowResult(success=False, error=f"Action failed: {str(e)}")`;
    
    case 'condition':
      return `    def ${funcName}(self, context: Dict[str, Any]) -> WorkflowResult:
        """${node.description}"""
        logger.info("Condition: ${node.title}")
        
        # Evaluate condition (customize logic)
        condition_met = True  # Replace with actual condition
        
        return WorkflowResult(success=True, data={'condition_met': condition_met})`;
    
    case 'data':
      return `    def ${funcName}(self, context: Dict[str, Any]) -> WorkflowResult:
        """${node.description}"""
        logger.info("Data Transform: ${node.title}")
        
        # Transform data (customize logic)
        transformed = context.copy()
        
        return WorkflowResult(success=True, data=transformed)`;
    
    default:
      return `    def ${funcName}(self, context: Dict[str, Any]) -> WorkflowResult:
        """${node.description}"""
        logger.info("Step: ${node.title}")
        return WorkflowResult(success=True, data=context)`;
  }
}

function sanitizePythonName(name: string): string {
  return name.toLowerCase().replace(/[^a-z0-9]/g, '_');
}

// === TypeScript Standalone Export ===
function generateTypeScriptCode(nodes: WorkflowNodeData[], workflowName: string) {
  return `/**
 * ${workflowName} - FlowFuse Workflow
 * Auto-generated TypeScript implementation
 */

interface WorkflowResult<T = any> {
  success: boolean;
  data?: T;
  error?: string;
}

interface WorkflowContext {
  [key: string]: any;
}

export class ${workflowName.replace(/[^a-zA-Z0-9]/g, '')}Workflow {
  private config: Record<string, string>;

  constructor(config?: Record<string, string>) {
    this.config = config || {
      openaiApiKey: process.env.OPENAI_API_KEY || '',
      webhookUrl: process.env.WEBHOOK_URL || '',
    };
  }

${nodes.map((node, idx) => generateTypeScriptNodeFunction(node, idx)).join('\n\n')}

  async execute(inputData: any): Promise<WorkflowResult> {
    console.log('üöÄ Starting workflow execution');
    const context: WorkflowContext = { input: inputData };

    try {
${nodes.map((node, idx) => `      // Step ${idx + 1}: ${node.title}
      const result${idx} = await this.${sanitizeTypescriptName(node.title)}(context);
      if (!result${idx}.success) {
        return result${idx};
      }
      context.step_${idx + 1} = result${idx}.data;`).join('\n\n')}

      console.log('‚úÖ Workflow completed successfully');
      return { success: true, data: context };

    } catch (error) {
      console.error('‚ùå Workflow failed:', error);
      return {
        success: false,
        error: error instanceof Error ? error.message : 'Unknown error'
      };
    }
  }
}

// Example usage
if (require.main === module) {
  const workflow = new ${workflowName.replace(/[^a-zA-Z0-9]/g, '')}Workflow();
  
  workflow.execute({ sample: 'data' })
    .then(result => {
      if (result.success) {
        console.log('Result:', JSON.stringify(result.data, null, 2));
      } else {
        console.error('Error:', result.error);
        process.exit(1);
      }
    });
}
`;
}

function generateTypeScriptNodeFunction(node: WorkflowNodeData, index: number): string {
  const funcName = sanitizeTypescriptName(node.title);
  
  switch (node.type) {
    case 'trigger':
      return `  private async ${funcName}(context: WorkflowContext): Promise<WorkflowResult> {
    console.log('üì• Trigger: ${node.title}');
    // ${node.description}
    return { success: true, data: context.input };
  }`;
    
    case 'ai':
      return `  private async ${funcName}(context: WorkflowContext): Promise<WorkflowResult> {
    console.log('ü§ñ AI Processing: ${node.title}');
    // ${node.description}
    
    if (!this.config.openaiApiKey) {
      return { success: false, error: 'OpenAI API key not configured' };
    }

    try {
      const response = await fetch('https://api.openai.com/v1/chat/completions', {
        method: 'POST',
        headers: {
          'Authorization': \`Bearer \${this.config.openaiApiKey}\`,
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          model: 'gpt-4',
          messages: [
            { role: 'system', content: 'You are a helpful assistant' },
            { role: 'user', content: JSON.stringify(context) }
          ]
        })
      });

      const data = await response.json();
      return { success: true, data: { aiResponse: data.choices[0].message.content } };
    } catch (error) {
      return { success: false, error: \`AI processing failed: \${error}\` };
    }
  }`;
    
    case 'action':
      return `  private async ${funcName}(context: WorkflowContext): Promise<WorkflowResult> {
    console.log('‚ö° Action: ${node.title}');
    // ${node.description}
    
    try {
      const response = await fetch(this.config.webhookUrl || 'https://example.com/webhook', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(context)
      });

      const data = await response.json();
      return { success: true, data };
    } catch (error) {
      return { success: false, error: \`Action failed: \${error}\` };
    }
  }`;
    
    case 'condition':
      return `  private async ${funcName}(context: WorkflowContext): Promise<WorkflowResult> {
    console.log('üîÄ Condition: ${node.title}');
    // ${node.description}
    
    const conditionMet = true; // Customize condition logic
    return { success: true, data: { conditionMet } };
  }`;
    
    case 'data':
      return `  private async ${funcName}(context: WorkflowContext): Promise<WorkflowResult> {
    console.log('üîÑ Data Transform: ${node.title}');
    // ${node.description}
    
    const transformed = { ...context }; // Customize transformation
    return { success: true, data: transformed };
  }`;
    
    default:
      return `  private async ${funcName}(context: WorkflowContext): Promise<WorkflowResult> {
    console.log('üìå Step: ${node.title}');
    return { success: true, data: context };
  }`;
  }
}

function sanitizeTypescriptName(name: string): string {
  return name.replace(/[^a-zA-Z0-9]/g, '').charAt(0).toLowerCase() + 
         name.replace(/[^a-zA-Z0-9]/g, '').slice(1);
}

// === Docker Export ===
function generateDockerfile(nodes: WorkflowNodeData[]) {
  const hasAI = nodes.some(n => n.type === 'ai');
  
  return `FROM python:3.11-slim

WORKDIR /app

# Install dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy workflow code
COPY workflow.py .

# Set environment variables
ENV PYTHONUNBUFFERED=1

# Health check
HEALTHCHECK --interval=30s --timeout=3s \\
  CMD python -c "print('healthy')" || exit 1

# Run workflow
CMD ["python", "workflow.py"]
`;
}

function generateDockerCompose(workflowName: string) {
  return `version: '3.8'

services:
  workflow:
    build: .
    container_name: ${workflowName.toLowerCase().replace(/[^a-z0-9]/g, '-')}
    environment:
      - OPENAI_API_KEY=\${OPENAI_API_KEY}
      - WEBHOOK_URL=\${WEBHOOK_URL}
    restart: unless-stopped
    networks:
      - workflow-net

networks:
  workflow-net:
    driver: bridge
`;
}

// === GitHub Actions Export ===
function generateGitHubAction(nodes: WorkflowNodeData[], workflowName: string) {
  return `name: ${workflowName}

on:
  workflow_dispatch:
    inputs:
      input_data:
        description: 'Input data for workflow'
        required: true
        type: string
  schedule:
    - cron: '0 */6 * * *'  # Run every 6 hours

jobs:
  execute-workflow:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          pip install requests
      
      - name: Execute workflow
        env:
          OPENAI_API_KEY: \${{ secrets.OPENAI_API_KEY }}
          WEBHOOK_URL: \${{ secrets.WEBHOOK_URL }}
        run: |
          python workflow.py
      
      - name: Upload results
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: workflow-results
          path: results.json
          retention-days: 30
`;
}

// === Manifest Generation ===
function generateManifest(nodes: WorkflowNodeData[], workflowName: string, platform: ExportPlatform) {
  const coreNodes = nodes.filter(n => (n as any).group === 'Core' || !(n as any).group);
  const optionalNodes = nodes.filter(n => (n as any).group === 'Optional Connectors');
  const systemNodes = nodes.filter(n => (n as any).group === 'System Services');
  
  const dependencies: string[] = [];
  nodes.forEach(node => {
    if (node.type === 'ai') dependencies.push('OpenAI API');
    if (node.type === 'action') {
      const connector = node.config?.connector;
      if (connector) dependencies.push(connector);
    }
  });

  return {
    workflow_name: workflowName,
    version: '1.0.0',
    platforms: [platform],
    dependencies: [...new Set(dependencies)],
    core_nodes: coreNodes.length,
    optional_nodes: optionalNodes.length,
    system_nodes: systemNodes.length,
    default_runtime: platform,
    entry_point: getEntryPoint(platform),
    health_check: `/health`,
    architecture: {
      event_driven: true,
      state_management: true,
      circuit_breakers: systemNodes.some(n => n.title.includes('Circuit') || n.title.includes('Error')),
      rate_limiting: systemNodes.some(n => n.title.includes('Rate') || n.title.includes('Limit')),
    },
    integrations: nodes
      .filter(n => n.config?.connector)
      .map(n => ({
        name: n.config?.connector,
        optional: n.config?.optional || false,
        priority: (n as any).priority || 0.5,
        justification: n.config?.justification
      }))
  };
}

function getEntryPoint(platform: ExportPlatform): string {
  const entryPoints: Record<ExportPlatform, string> = {
    'n8n': 'workflow.json',
    'make': 'scenario.json',
    'python': 'workflow.py',
    'typescript': 'workflow.ts',
    'docker': 'docker-compose.yml',
    'github-actions': '.github/workflows/workflow.yml',
    'supabase-function': 'index.ts',
    'standalone': 'main.py',
    'zapier': 'zapier.json'
  };
  return entryPoints[platform];
}

// === Health Check Generation ===
function generateHealthCheck(workflowName: string) {
  return `{
  "status": "healthy",
  "workflow": "${workflowName}",
  "version": "1.0.0",
  "uptime": 0,
  "last_execution": null,
  "total_executions": 0,
  "success_rate": 100,
  "average_duration_ms": 0,
  "active_connections": {
    "ai_providers": [],
    "databases": [],
    "apis": []
  }
}`;
}

// === Deploy Script Generation ===
function generateDeployScript(platform: ExportPlatform, workflowName: string): string {
  switch (platform) {
    case 'supabase-function':
      return `#!/bin/bash
# FlowFuse Deployment Script for Supabase

echo "üöÄ Deploying ${workflowName} to Supabase..."

# Check if Supabase CLI is installed
if ! command -v supabase &> /dev/null; then
    echo "‚ùå Supabase CLI not found. Install it first:"
    echo "npm install -g supabase"
    exit 1
fi

# Check if project is linked
if [ ! -f ".supabase/config.toml" ]; then
    echo "‚ùå Not linked to a Supabase project"
    echo "Run: supabase link --project-ref your-project-ref"
    exit 1
fi

# Deploy function
echo "üì¶ Deploying edge function..."
supabase functions deploy ${workflowName.toLowerCase().replace(/[^a-z0-9]/g, '-')}

# Set secrets if .env exists
if [ -f ".env" ]; then
    echo "üîê Setting environment secrets..."
    while IFS='=' read -r key value; do
        if [ ! -z "$key" ] && [ ! -z "$value" ]; then
            supabase secrets set "$key=$value" --quiet
        fi
    done < .env
fi

echo "‚úÖ Deployment complete!"
echo "üìç Function URL: https://your-project.supabase.co/functions/v1/${workflowName.toLowerCase().replace(/[^a-z0-9]/g, '-')}"
`;

    case 'docker':
      return `#!/bin/bash
# FlowFuse Deployment Script for Docker

echo "üöÄ Building and deploying ${workflowName}..."

# Load environment variables
if [ -f ".env" ]; then
    export $(cat .env | xargs)
else
    echo "‚ö†Ô∏è  No .env file found, using defaults"
fi

# Build image
echo "üî® Building Docker image..."
docker build -t ${workflowName.toLowerCase().replace(/[^a-z0-9]/g, '-')} .

# Stop existing container
echo "üõë Stopping existing container..."
docker-compose down

# Start new container
echo "‚ñ∂Ô∏è  Starting container..."
docker-compose up -d

# Show logs
echo "üìã Container logs:"
docker-compose logs -f

echo "‚úÖ Deployment complete!"
`;

    case 'python':
      return `#!/bin/bash
# FlowFuse Deployment Script for Python

echo "üöÄ Setting up ${workflowName}..."

# Create virtual environment
python3 -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Load environment
if [ ! -f ".env" ]; then
    cp .env.example .env
    echo "‚ö†Ô∏è  Please edit .env with your credentials"
    exit 1
fi

# Run workflow
echo "‚ñ∂Ô∏è  Running workflow..."
python workflow.py

echo "‚úÖ Execution complete!"
`;

    default:
      return `#!/bin/bash
echo "üöÄ Deploying ${workflowName}..."
echo "‚ö†Ô∏è  Please follow platform-specific instructions in README.md"
`;
  }
}

// === Enhanced README with Optional Connectors ===
function generateEnhancedReadme(
  workflowName: string,
  platform: ExportPlatform,
  nodes: WorkflowNodeData[]
): string {
  const optionalNodes = nodes.filter(n => n.config?.optional === true);
  const coreNodes = nodes.filter(n => !n.config?.optional);
  
  return `# üöÄ FlowFuse Business Workflow Export
**Workflow Name:** ${workflowName}  
**Version:** 1.0.0  
**Platform:** ${getPlatformDisplayName(platform)}

## üìã Architecture Overview

This workflow combines the best practices from OpenDevin, LangGraph, and Autogen Studio:
- **Event-driven execution** with real-time monitoring
- **State management** with checkpointing for resumability
- **Circuit breakers** for fault tolerance
- **Multi-agent orchestration** with intelligent handoffs

### Core Nodes (${coreNodes.length})
${coreNodes.map(n => `- **${n.title}** (${n.type}): ${n.description}`).join('\n')}

### Optional Connectors (${optionalNodes.length})
${optionalNodes.length > 0 ? optionalNodes.map(n => 
  `- **${n.title}** (Priority: ${(n as any).priority || 0.5}): ${n.config?.justification || n.description}`
).join('\n') : '*No optional connectors configured*'}

## üöÄ Quick Start

\`\`\`bash
# 1. Configure environment
cp .env.example .env
# Edit .env with your API keys

# 2. Deploy
chmod +x deploy.sh
./deploy.sh

# 3. Monitor
curl http://localhost:3000/health
\`\`\`

## ‚öôÔ∏è Configuration

### Required Environment Variables
${generateRequiredEnvDocs(nodes)}

### Optional Connectors
${generateOptionalConnectorDocs(optionalNodes)}

## üè• Health Monitoring

Access the health endpoint to check workflow status:
\`\`\`bash
GET /health
\`\`\`

Response:
\`\`\`json
{
  "status": "healthy",
  "workflow": "${workflowName}",
  "uptime": 86400,
  "success_rate": 98.5,
  "active_connections": {...}
}
\`\`\`

## üîß Troubleshooting

### Circuit Breaker Opened
If you see "Circuit breaker open" errors:
1. Check external service health
2. Review recent error logs
3. Wait for automatic reset (60s)
4. Or manually reset via \`/reset-circuit\`

### Rate Limit Exceeded
- Default: 60 requests/minute per connector
- Configurable via \`RATE_LIMIT_MAX\` environment variable
- Errors are automatically retried with exponential backoff

## üìä Monitoring & Analytics

View execution logs:
\`\`\`bash
# Real-time logs
tail -f logs/workflow.log

# Error aggregation
cat logs/errors.json | jq '.[] | select(.level == "error")'

# Performance metrics
cat logs/metrics.json | jq '.average_duration_ms'
\`\`\`

## üîÑ Updating

To update the workflow:
1. Export new version from FlowFuse
2. Replace source files
3. Run \`./deploy.sh\` again
4. Monitor health endpoint

## üìö Support

- Documentation: https://flowfuse.ai/docs
- Community: https://flowfuse.ai/community
- Issues: https://github.com/flowfuse/flowfuse/issues

---

*Generated by FlowFuse v1.0.0 - Universal Orchestration Framework*
`;
}

function getPlatformDisplayName(platform: ExportPlatform): string {
  const names: Record<ExportPlatform, string> = {
    'n8n': 'n8n (Self-hosted Automation)',
    'make': 'Make.com (Cloud Automation)',
    'python': 'Python (Standalone)',
    'typescript': 'TypeScript/Node.js',
    'docker': 'Docker (Containerized)',
    'github-actions': 'GitHub Actions (CI/CD)',
    'supabase-function': 'Supabase Functions (Serverless Edge)',
    'standalone': 'Standalone Application',
    'zapier': 'Zapier'
  };
  return names[platform];
}

function generateRequiredEnvDocs(nodes: WorkflowNodeData[]): string {
  const required: string[] = [];
  
  if (nodes.some(n => n.type === 'ai')) {
    required.push('- `OPENAI_API_KEY` - OpenAI API key for AI nodes');
  }
  if (nodes.some(n => n.type === 'action')) {
    required.push('- `WEBHOOK_URL` - Target webhook endpoint');
    required.push('- `API_KEY` - External service API key');
  }
  
  return required.length > 0 ? required.join('\n') : '*No required environment variables*';
}

function generateOptionalConnectorDocs(optionalNodes: WorkflowNodeData[]): string {
  if (optionalNodes.length === 0) {
    return '*No optional connectors - workflow uses only core functionality*';
  }
  
  return optionalNodes.map(node => `
### ${node.title}
- **Purpose:** ${node.config?.justification || node.description}
- **Priority:** ${(node as any).priority || 0.5} (${getPriorityLabel((node as any).priority || 0.5)})
- **Enable:** Set \`ENABLE_${node.title.toUpperCase().replace(/[^A-Z0-9]/g, '_')}=true\` in .env
- **Dependencies:** ${node.config?.dependencies?.join(', ') || 'None'}
`).join('\n');
}

function getPriorityLabel(priority: number): string {
  if (priority >= 0.8) return 'Highly Recommended';
  if (priority >= 0.5) return 'Useful';
  return 'Optional';
}

// === Supabase Config Generation ===
function generateSupabaseConfig(workflowName: string): string {
  const functionName = workflowName.toLowerCase().replace(/[^a-z0-9]/g, '-');
  return `project_id = "your-project-id"

[functions.${functionName}]
verify_jwt = false  # Set to true if authentication required
`;
}

// === Config YAML Generation ===
function generateConfigYAML(nodes: WorkflowNodeData[]): string {
  const optionalNodes = nodes.filter(n => n.config?.optional === true);
  
  return `# FlowFuse Workflow Configuration

workflow:
  name: "FlowFuse Workflow"
  version: "1.0.0"

# Optional Connectors
optional_connectors:
${optionalNodes.length > 0 ? optionalNodes.map(n => `  - name: "${n.title}"
    enabled: false  # Set to true to enable
    priority: ${(n as any).priority || 0.5}
`).join('') : '  # No optional connectors configured\n'}

# Circuit Breaker Settings
circuit_breaker:
  failure_threshold: 5
  reset_timeout_ms: 60000
  half_open_max_calls: 3

# Rate Limiting
rate_limit:
  max_requests_per_minute: 60
  burst_size: 10

# Logging
logging:
  level: "info"
  format: "json"
  destination: "logs/workflow.log"

# Monitoring
monitoring:
  health_check_interval_ms: 30000
  metrics_enabled: true
  metrics_port: 9090
`;
}

// === Security & Guardrails Report Generation ===
function generateSecurityReport(
  workflowName: string,
  nodes: WorkflowNodeData[],
  metadata: GuardrailMetadata
): string {
  const { explanations = [], complianceStandards = [], riskScore, policyAnalysis } = metadata;
  
  const getRiskLevel = (score?: number) => {
    if (!score) return { level: 'Unknown', color: 'gray', emoji: '‚ùì' };
    if (score <= 30) return { level: 'Low', color: 'green', emoji: '‚úÖ' };
    if (score <= 60) return { level: 'Medium', color: 'yellow', emoji: '‚ö†Ô∏è' };
    return { level: 'High', color: 'red', emoji: 'üö®' };
  };

  const risk = getRiskLevel(riskScore);
  const guardrailNodes = nodes.filter(n => 
    n.type === 'security' || 
    n.type === 'guardrail' ||
    n.title.toLowerCase().includes('guardrail') ||
    n.title.toLowerCase().includes('validation') ||
    n.title.toLowerCase().includes('rate limit') ||
    n.title.toLowerCase().includes('security check') ||
    n.title.toLowerCase().includes('compliance')
  );

  return `# üîê Security & Guardrails Report
**Workflow:** ${workflowName}  
**Generated:** ${new Date().toISOString()}  
**Risk Assessment:** ${risk.emoji} **${risk.level} Risk** ${riskScore ? `(Score: ${riskScore}/100)` : ''}

---

## Executive Summary

This report provides a comprehensive security analysis of the "${workflowName}" workflow, including automated guardrails, compliance requirements, and security recommendations. All guardrails have been injected and configured based on detected data types, business logic, and regulatory requirements.

### Key Findings

- **Total Workflow Nodes:** ${nodes.length}
- **Security Guardrails:** ${guardrailNodes.length}
- **Compliance Standards:** ${complianceStandards.length > 0 ? complianceStandards.join(', ') : 'None detected'}
- **Risk Score:** ${riskScore ?? 'Not calculated'}

---

## üõ°Ô∏è Implemented Guardrails

${guardrailNodes.length > 0 ? guardrailNodes.map((node, index) => `
### ${index + 1}. ${node.title} (${node.type})

**Description:** ${node.description}

**Purpose:** ${explanations.find(e => e.nodeId === node.id)?.reason || 'Protects workflow integrity and ensures compliance'}

**Configuration:**
\`\`\`yaml
${node.config ? Object.entries(node.config).map(([key, value]) => `${key}: ${JSON.stringify(value)}`).join('\n') : 'No configuration specified'}
\`\`\`

**Reasoning:**
${explanations.find(e => e.nodeId === node.id)?.explanation || 'This guardrail was automatically injected to ensure workflow security and reliability.'}

---
`).join('\n') : '*No explicit security guardrails detected. Consider adding input validation, rate limiting, and output sanitization nodes.*'}

## üìä Policy Analysis

${policyAnalysis ? `
### Detected Data Types
${policyAnalysis.detectedDataTypes && policyAnalysis.detectedDataTypes.length > 0 
  ? policyAnalysis.detectedDataTypes.map(dt => `- **${dt}**`).join('\n')
  : '*No sensitive data types detected*'}

### Compliance Requirements
${policyAnalysis.complianceStandards && policyAnalysis.complianceStandards.length > 0
  ? policyAnalysis.complianceStandards.map(cs => `- **${cs}**`).join('\n')
  : '*No specific compliance standards detected*'}

### Potential Risks

${policyAnalysis.potentialRisks && policyAnalysis.potentialRisks.length > 0
  ? policyAnalysis.potentialRisks.map((risk, idx) => `
#### ${idx + 1}. ${risk.risk}
- **Severity:** ${risk.severity}
- **Mitigation:** ${risk.mitigation}
`).join('\n')
  : '*No major risks identified in current workflow configuration*'}

### Recommended Additional Guardrails

${policyAnalysis.recommendedGuardrails && policyAnalysis.recommendedGuardrails.length > 0
  ? policyAnalysis.recommendedGuardrails.map((gr, idx) => `
#### ${idx + 1}. ${gr.type}
- **Reason:** ${gr.reason}
- **Implementation:** ${gr.implementation}
`).join('\n')
  : '*All recommended guardrails have been implemented*'}
` : '*Policy analysis not available. Run workflow through compliance scanner for detailed analysis.*'}

## üéØ Compliance Standards

${complianceStandards.length > 0 ? `
This workflow has been configured to comply with the following standards:

${complianceStandards.map(std => {
  const standardInfo = getComplianceInfo(std);
  return `### ${standardInfo.name}

**Description:** ${standardInfo.description}

**Key Requirements:**
${standardInfo.requirements.map(req => `- ${req}`).join('\n')}

**Implementation Status:** ${standardInfo.implemented ? '‚úÖ Implemented' : '‚ö†Ô∏è Partial'}
`;
}).join('\n')}
` : '*No specific compliance standards detected. If your workflow handles sensitive data (PII, PHI, PCI), ensure you configure appropriate compliance guardrails.*'}

## üîç Security Best Practices

### Input Validation
${guardrailNodes.some(n => n.title.toLowerCase().includes('input') && n.title.toLowerCase().includes('validation'))
  ? '‚úÖ Input validation is implemented'
  : '‚ö†Ô∏è **Recommendation:** Add input validation to prevent injection attacks and malformed data'}

### Rate Limiting
${guardrailNodes.some(n => n.title.toLowerCase().includes('rate') && n.title.toLowerCase().includes('limit'))
  ? '‚úÖ Rate limiting is configured'
  : '‚ö†Ô∏è **Recommendation:** Implement rate limiting to prevent abuse and ensure fair resource usage'}

### Output Sanitization
${guardrailNodes.some(n => n.title.toLowerCase().includes('output') && n.title.toLowerCase().includes('validation'))
  ? '‚úÖ Output validation is active'
  : '‚ö†Ô∏è **Recommendation:** Add output validation to prevent data leakage and ensure data quality'}

### Security Checks
${guardrailNodes.some(n => n.type === 'security' || n.title.toLowerCase().includes('security'))
  ? '‚úÖ Security checks are in place'
  : '‚ö†Ô∏è **Recommendation:** Implement security checks for authentication, authorization, and data access'}

## üìà Risk Mitigation Strategy

Based on the risk score of **${riskScore ?? 'N/A'}**, we recommend:

${risk.level === 'High' ? `
### Immediate Actions Required üö®
1. **Review all input sources** - Implement strict validation
2. **Add authentication** - Ensure all endpoints require valid credentials
3. **Enable audit logging** - Track all workflow executions
4. **Implement circuit breakers** - Prevent cascade failures
5. **Add encryption** - Protect data in transit and at rest
` : risk.level === 'Medium' ? `
### Recommended Improvements ‚ö†Ô∏è
1. **Enhance monitoring** - Add detailed execution tracking
2. **Implement retry logic** - Handle transient failures gracefully
3. **Add health checks** - Monitor workflow component status
4. **Review error handling** - Ensure sensitive data isn't leaked in errors
` : `
### Maintenance Actions ‚úÖ
1. **Regular security audits** - Review guardrails quarterly
2. **Update dependencies** - Keep all packages current
3. **Monitor performance** - Track execution times and resource usage
4. **Document changes** - Maintain security changelog
`}

## üöÄ Deployment Checklist

Before deploying this workflow to production:

- [ ] Review all guardrail configurations
- [ ] Configure environment variables securely
- [ ] Enable audit logging
- [ ] Set up monitoring and alerting
- [ ] Test with production-like data volumes
- [ ] Perform security scan
- [ ] Document incident response procedures
- [ ] Configure backup and recovery
- [ ] Review access controls
- [ ] Verify compliance requirements

## üìû Support & Resources

- **Security Documentation:** https://flowfuse.ai/docs/security
- **Compliance Guide:** https://flowfuse.ai/docs/compliance
- **Best Practices:** https://flowfuse.ai/docs/best-practices
- **Community Support:** https://flowfuse.ai/community

---

**Report Version:** 1.0.0  
**Generated by:** FlowFuse Security Scanner  
**Next Review:** ${new Date(Date.now() + 90 * 24 * 60 * 60 * 1000).toISOString().split('T')[0]}
`;
}

function getComplianceInfo(standard: string) {
  const standards: Record<string, any> = {
    'GDPR': {
      name: 'GDPR (General Data Protection Regulation)',
      description: 'EU regulation on data protection and privacy',
      requirements: [
        'Obtain explicit consent for data processing',
        'Implement data minimization principles',
        'Ensure data portability and right to erasure',
        'Maintain data processing records',
        'Report breaches within 72 hours'
      ],
      implemented: true
    },
    'HIPAA': {
      name: 'HIPAA (Health Insurance Portability and Accountability Act)',
      description: 'US law protecting sensitive patient health information',
      requirements: [
        'Encrypt PHI in transit and at rest',
        'Implement access controls and audit logs',
        'Conduct regular risk assessments',
        'Maintain business associate agreements',
        'Ensure physical and technical safeguards'
      ],
      implemented: true
    },
    'PCI-DSS': {
      name: 'PCI-DSS (Payment Card Industry Data Security Standard)',
      description: 'Security standard for organizations handling credit cards',
      requirements: [
        'Build and maintain secure networks',
        'Protect cardholder data with encryption',
        'Implement strong access control measures',
        'Regularly monitor and test networks',
        'Maintain information security policy'
      ],
      implemented: true
    },
    'SOC2': {
      name: 'SOC 2 (Service Organization Control 2)',
      description: 'Trust service criteria for security, availability, and confidentiality',
      requirements: [
        'Implement security policies and procedures',
        'Control system access and authorization',
        'Monitor system operations and performance',
        'Manage system changes and incidents',
        'Ensure business continuity and disaster recovery'
      ],
      implemented: true
    }
  };
  
  return standards[standard] || {
    name: standard,
    description: 'Custom compliance standard',
    requirements: ['Review specific requirements for this standard'],
    implemented: false
  };
}

// === Main Export Function ===
export async function exportWorkflowForBusiness(
  nodes: WorkflowNodeData[],
  workflowName: string,
  options: ExportOptions
): Promise<Blob> {
  const zip = new JSZip();
  
  // Generate manifest
  const manifest = generateManifest(nodes, workflowName, options.platform);
  zip.file('manifest.json', JSON.stringify(manifest, null, 2));
  
  // Generate health check
  zip.file('logs/healthcheck.json', generateHealthCheck(workflowName));
  
  // Generate deploy script
  zip.file('deploy.sh', generateDeployScript(options.platform, workflowName));
  
  // Generate enhanced README
  zip.file('README.md', generateEnhancedReadme(workflowName, options.platform, nodes));
  
  // Generate Security & Guardrails Report
  if (options.guardrailMetadata) {
    zip.file('SECURITY_REPORT.md', generateSecurityReport(
      workflowName,
      nodes,
      options.guardrailMetadata
    ));
  }
  
  // Platform-specific files
  switch (options.platform) {
    case 'n8n':
      zip.file('deploy/n8n/workflow.json', JSON.stringify(generateN8NWorkflow(nodes, workflowName), null, 2));
      break;
    
    case 'make':
      zip.file('deploy/make/scenario.json', JSON.stringify(generateMakeScenario(nodes, workflowName), null, 2));
      break;
    
    case 'python':
      zip.file('deploy/python/workflow.py', generatePythonScript(nodes, workflowName));
      zip.file('deploy/python/requirements.txt', 'requests>=2.31.0\npython-dotenv>=1.0.0');
      break;
    
    case 'typescript':
      zip.file('deploy/typescript/workflow.ts', generateTypeScriptCode(nodes, workflowName));
      zip.file('deploy/typescript/package.json', generatePackageJson(workflowName));
      break;
    
    case 'docker':
      zip.file('deploy/docker/workflow.py', generatePythonScript(nodes, workflowName));
      zip.file('deploy/docker/Dockerfile', generateDockerfile(nodes));
      zip.file('deploy/docker/docker-compose.yml', generateDockerCompose(workflowName));
      zip.file('deploy/docker/requirements.txt', 'requests>=2.31.0');
      break;
    
    case 'github-actions':
      zip.file('deploy/github-actions/workflow.py', generatePythonScript(nodes, workflowName));
      zip.file('deploy/github-actions/.github/workflows/workflow.yml', generateGitHubAction(nodes, workflowName));
      zip.file('deploy/github-actions/requirements.txt', 'requests>=2.31.0');
      break;
    
    case 'supabase-function':
      zip.file('deploy/supabase/functions/index.ts', generateSupabaseFunction(nodes, workflowName));
      zip.file('deploy/supabase/config.toml', generateSupabaseConfig(workflowName));
      break;
  }
  
  // Environment template
  zip.file('.env.example', generateEnvExample(nodes));
  
  // Config file for optional connectors
  zip.file('config.yaml', generateConfigYAML(nodes));
  
  // Always include original FlowFuse workflow
  zip.file('flowfuse-workflow.json', JSON.stringify({
    name: workflowName,
    version: '1.0.0',
    platform: 'FlowFuse',
    exportedAt: new Date().toISOString(),
    nodes: nodes
  }, null, 2));
  
  return await zip.generateAsync({ type: 'blob' });
}

// Helper functions for README generation
function generateN8NReadme(workflowName: string): string {
  return `# ${workflowName} - n8n Workflow

## Import Instructions

1. Open your n8n instance
2. Click "New Workflow"
3. Click the menu (‚ãÆ) ‚Üí "Import from File"
4. Select \`workflow.json\`
5. Configure credentials for each node
6. Activate the workflow

## Configuration

Configure these credentials in n8n:
- Webhook credentials
- API keys for external services
- Database connections

## Testing

1. Trigger the webhook manually
2. Check execution history
3. Review node outputs

For support: https://flowfuse.ai/support
`;
}

function generateMakeReadme(workflowName: string): string {
  return `# ${workflowName} - Make.com Scenario

## Import Instructions

1. Log in to Make.com
2. Navigate to Scenarios
3. Click "Create a new scenario"
4. Click the menu (‚ãÆ) ‚Üí "Import Blueprint"
5. Upload \`scenario.json\`
6. Configure connections for each module

## Configuration

Set up these connections:
- Custom Webhook
- HTTP requests
- External service APIs

## Activation

1. Review all modules
2. Test with sample data
3. Activate the scenario

For support: https://flowfuse.ai/support
`;
}

function generatePythonReadme(workflowName: string): string {
  return `# ${workflowName} - Python Workflow

## Setup

\`\`\`bash
# Install dependencies
pip install -r requirements.txt

# Configure environment
cp .env.example .env
# Edit .env with your credentials

# Run workflow
python workflow.py
\`\`\`

## Deployment Options

### Cloud Functions
- AWS Lambda
- Google Cloud Functions
- Azure Functions

### Cron Job
\`\`\`bash
# Add to crontab
0 */6 * * * cd /path/to/workflow && python workflow.py
\`\`\`

### Docker
\`\`\`bash
docker build -t ${workflowName.toLowerCase()} .
docker run --env-file .env ${workflowName.toLowerCase()}
\`\`\`

For support: https://flowfuse.ai/support
`;
}

function generateTypeScriptReadme(workflowName: string): string {
  return `# ${workflowName} - TypeScript Workflow

## Setup

\`\`\`bash
# Install dependencies
npm install

# Configure environment
cp .env.example .env
# Edit .env with your credentials

# Run workflow
npm start
\`\`\`

## Deployment

This workflow can be deployed to:
- Vercel Serverless Functions
- AWS Lambda (Node.js runtime)
- Google Cloud Functions
- Self-hosted Node.js server

For support: https://flowfuse.ai/support
`;
}

function generateDockerReadme(workflowName: string): string {
  return `# ${workflowName} - Docker Deployment

## Quick Start

\`\`\`bash
# Configure environment
cp .env.example .env
# Edit .env with your credentials

# Build and run
docker-compose up -d

# View logs
docker-compose logs -f

# Stop
docker-compose down
\`\`\`

## Production Deployment

Deploy to any container orchestration platform:
- Kubernetes
- Docker Swarm
- AWS ECS
- Google Cloud Run

For support: https://flowfuse.ai/support
`;
}

function generateGitHubActionsReadme(workflowName: string): string {
  return `# ${workflowName} - GitHub Actions

## Setup

1. Push this repository to GitHub
2. Go to Settings ‚Üí Secrets and variables ‚Üí Actions
3. Add secrets:
   - \`OPENAI_API_KEY\`
   - \`WEBHOOK_URL\`
   - (Add others as needed)

## Usage

### Manual Trigger
1. Go to Actions tab
2. Select "${workflowName}"
3. Click "Run workflow"
4. Enter input data

### Scheduled Execution
Workflow runs automatically every 6 hours (configurable in workflow.yml)

## Monitoring

View execution logs in the Actions tab.

For support: https://flowfuse.ai/support
`;
}

function generateSupabaseFunctionReadme(workflowName: string): string {
  return `# ${workflowName} - Supabase Edge Function

## Deployment

\`\`\`bash
# Install Supabase CLI
npm install -g supabase

# Link to your project
supabase link --project-ref your-project-ref

# Deploy function
supabase functions deploy ${workflowName.toLowerCase().replace(/[^a-z0-9]/g, '-')}

# Set secrets
supabase secrets set OPENAI_API_KEY=your_key
\`\`\`

## Invoke

\`\`\`bash
curl -L -X POST 'https://your-project.supabase.co/functions/v1/${workflowName.toLowerCase().replace(/[^a-z0-9]/g, '-')}' \\
  -H 'Authorization: Bearer YOUR_ANON_KEY' \\
  -H 'Content-Type: application/json' \\
  --data '{"input": "your data"}'
\`\`\`

For support: https://flowfuse.ai/support
`;
}

function generateSupabaseFunction(nodes: WorkflowNodeData[], workflowName: string): string {
  return `import { serve } from "https://deno.land/std@0.168.0/http/server.ts";

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
};

serve(async (req) => {
  if (req.method === 'OPTIONS') {
    return new Response(null, { headers: corsHeaders });
  }

  try {
    const { input } = await req.json();
    console.log('üöÄ Starting workflow execution');

    let context = { input };

${nodes.map((node, idx) => `    // Step ${idx + 1}: ${node.title}
    console.log('${node.title}');
    // TODO: Implement ${node.type} logic
    context.step_${idx + 1} = { success: true };`).join('\n\n')}

    console.log('‚úÖ Workflow completed');
    return new Response(
      JSON.stringify({ success: true, data: context }),
      { headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
    );

  } catch (error) {
    console.error('‚ùå Workflow failed:', error);
    return new Response(
      JSON.stringify({ success: false, error: error.message }),
      { 
        status: 500,
        headers: { ...corsHeaders, 'Content-Type': 'application/json' }
      }
    );
  }
});`;
}

function generateEnvExample(nodes: WorkflowNodeData[]): string {
  const hasAI = nodes.some(n => n.type === 'ai');
  const hasActions = nodes.some(n => n.type === 'action');
  
  let env = '# Environment Variables\n\n';
  
  if (hasAI) {
    env += '# AI Services\nOPENAI_API_KEY=your_openai_key_here\n\n';
  }
  
  if (hasActions) {
    env += '# Integrations\nWEBHOOK_URL=https://your-webhook.com\n';
    env += 'API_KEY=your_api_key_here\n\n';
  }
  
  return env;
}

function generatePackageJson(workflowName: string): string {
  return JSON.stringify({
    name: workflowName.toLowerCase().replace(/[^a-z0-9]/g, '-'),
    version: '1.0.0',
    description: 'FlowFuse workflow',
    main: 'workflow.ts',
    scripts: {
      start: 'ts-node workflow.ts',
      build: 'tsc workflow.ts'
    },
    dependencies: {
      'dotenv': '^16.0.0'
    },
    devDependencies: {
      '@types/node': '^20.0.0',
      'ts-node': '^10.9.0',
      'typescript': '^5.0.0'
    }
  }, null, 2);
}
