/**
 * AI TRANSPARENCY & FAIR-USE STATEMENT
 * Remora Development | Remora Flow
 * Version: 1.0 | Generated: 2025-11-12
 * 
 * Remora Flow operates under principles of transparency, 
 * fair use, and responsible AI development.
 * 
 * All workflows generated by this software are transformative interpretations created 
 * by analyzing publicly available content such as metadata, transcripts, and structural
 * cues from online videos, articles, or educational media.
 * 
 * This software does not store, reproduce, or distribute any copyrighted visual, audio, 
 * or text-based material. Instead, it extracts semantic patterns and converts them into 
 * new, original workflow structures for educational and productivity purposes.
 * 
 * LEGAL COMPLIANCE:
 * - U.S. Copyright Law (17 U.S.C. §107): Transformative use for commentary, analysis, and education
 * - YouTube Developer Policies (Section 5.B): No redistribution or unauthorized reuse of video content
 * - GDPR (Article 5.1.c): Data minimization, transparency, and user consent for all data processing
 * 
 * ETHICAL STANDARDS:
 * Remora Development ensures that all AI-driven interpretations serve accessibility, 
 * education, and cognitive empowerment. Users retain full control over all inputs, 
 * exports, and deletions of local or cloud-synced data.
 * 
 * © 2025 Remora Development. All rights reserved.
 * Contact: legal@remoradev.ai
 */

import "https://deno.land/x/xhr@0.1.0/mod.ts";
import { serve } from "https://deno.land/std@0.168.0/http/server.ts";
import { createClient } from 'https://esm.sh/@supabase/supabase-js@2.7.1';
import { injectGuardrailNodes, GUARDRAIL_SYSTEM_PROMPT } from "../_shared/guardrails.ts";

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
};

const MAX_IMAGE_SIZE = 10 * 1024 * 1024; // 10MB

serve(async (req) => {
  if (req.method === 'OPTIONS') {
    return new Response(null, { headers: corsHeaders });
  }

  try {
    console.log('Received image analysis request');
    
    const { images, image, existingWorkflow } = await req.json();
    
    // Support both single image (legacy) and multiple images
    const imageArray = images || (image ? [image] : []);
    
    // Input validation
    if (!imageArray || imageArray.length === 0) {
      return new Response(
        JSON.stringify({ error: 'No images provided' }),
        { status: 400, headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
      );
    }

    if (!Array.isArray(imageArray)) {
      return new Response(
        JSON.stringify({ error: 'Images must be an array' }),
        { status: 400, headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
      );
    }

    if (imageArray.length > 5) {
      return new Response(
        JSON.stringify({ error: 'Maximum 5 images allowed per request' }),
        { status: 400, headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
      );
    }

    // Validate each image
    for (let i = 0; i < imageArray.length; i++) {
      const img = imageArray[i];
      
      if (typeof img !== 'string') {
        return new Response(
          JSON.stringify({ error: `Image ${i + 1} must be a string (base64 or URL)` }),
          { status: 400, headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
        );
      }

      // Check image size for base64 images
      if (img.startsWith('data:')) {
        const base64Data = img.split(',')[1];
        const sizeInBytes = (base64Data.length * 3) / 4;
        if (sizeInBytes > MAX_IMAGE_SIZE) {
          return new Response(
            JSON.stringify({ error: `Image ${i + 1} exceeds maximum size of ${MAX_IMAGE_SIZE / 1024 / 1024}MB` }),
            { status: 400, headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
          );
        }
      }
    }

    console.log(`Analyzing ${imageArray.length} workflow image(s)...`);

    const LOVABLE_API_KEY = Deno.env.get('LOVABLE_API_KEY');
    if (!LOVABLE_API_KEY) {
      throw new Error('LOVABLE_API_KEY not configured');
    }

    // Create AbortController for timeout
    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), 55000); // 55s timeout (Edge Functions have 60s limit)

    try {
      // Build the content array with all images
      const userContent: any[] = [
        {
          type: 'text',
          text: imageArray.length > 1 
            ? `Analyze these ${imageArray.length} workflow images and combine them into a single cohesive workflow. Extract all nodes, connections, and workflow logic from all images. If there are overlapping or related concepts, merge them intelligently. Return structured JSON data.`
            : 'Analyze this workflow image and extract all nodes, connections, and workflow logic. Return structured JSON data.'
        }
      ];

      // Add all images to the content
      imageArray.forEach((img: string) => {
        userContent.push({
          type: 'image_url',
          image_url: {
            url: img // base64 data URL or https URL
          }
        });
      });

      // Use Gemini 2.5 Flash for vision analysis (free during promo)
      const response = await fetch('https://ai.gateway.lovable.dev/v1/chat/completions', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${LOVABLE_API_KEY}`,
          'Content-Type': 'application/json',
        },
        signal: controller.signal,
        body: JSON.stringify({
          model: 'google/gemini-2.5-flash',
          max_tokens: 16000,
          response_format: { type: 'json_object' },
          messages: [
            {
              role: 'system',
              content: `You are an Expert Workflow Understanding Engine. Analyze images containing workflows, diagrams, sketches, or process descriptions and extract structured workflow data.

${GUARDRAIL_SYSTEM_PROMPT}

${existingWorkflow ? `
IMPORTANT: You are IMPROVING an existing workflow. The user has provided an image to enhance their current workflow.

EXISTING WORKFLOW:
${JSON.stringify(existingWorkflow, null, 2)}

Your task:
1. Understand the existing workflow structure
2. Analyze the provided image(s) for new features/nodes
3. Integrate image insights with existing workflow
4. Keep relevant existing nodes
5. Add new nodes from the image
6. Maintain logical connections
7. Preserve node IDs for unchanged nodes
8. Generate new IDs only for new nodes
9. Explain what was improved/added in the insights
` : 'Your task:'}
1. Identify all workflow nodes (triggers, actions, conditions, data operations, AI steps) across ALL provided images
2. Detect connections and flow between nodes, even across different images
3. Extract node properties (titles, descriptions, types)
4. Infer logical relationships and dependencies
5. If multiple images are provided, intelligently combine them into a single cohesive workflow
6. Position nodes logically to show the combined flow
7. Generate a complete, executable workflow JSON

Return ONLY valid JSON in this exact format:
{
  "nodes": [
    {
      "id": "unique_id",
      "type": "trigger|action|condition|data|ai",
      "title": "Node Title",
      "description": "Detailed description of what this node does",
      "x": 100,
      "y": 100
    }
  ],
  "insights": "AI analysis of the workflow - what it does, how the images were combined, potential improvements, missing steps"
}

OUTPUT FORMAT:
- CRITICAL: Return ONLY valid, complete JSON - no markdown, no code blocks, no truncation
- CRITICAL: Ensure all JSON strings are properly closed and terminated
- CRITICAL: Keep responses under 12000 tokens to avoid truncation
- If the workflow is complex, prioritize core nodes and essential connections
- Use concise descriptions and explanations

IMPORTANT: Always include this AI Transparency & Fair-Use Statement at the end of your "insights" field or as a separate "disclaimer" field:

"AI TRANSPARENCY NOTICE: This workflow is a transformative interpretation generated by Remora Flow (Remora Development) for educational and productivity purposes. No copyrighted content was stored or redistributed. This analysis complies with U.S. Copyright Law (17 U.S.C. §107 - Fair Use), YouTube Developer Policies (Section 5.B), and GDPR (Article 5.1.c). All intellectual property rights remain with original creators. Users must ensure compliance with local laws and platform policies. © 2025 Remora Development | Contact: legal@remoradev.ai"`
            },
            {
              role: 'user',
              content: userContent
            }
          ],
          temperature: 0.3
        }),
      });

    clearTimeout(timeoutId);

    if (!response.ok) {
      if (response.status === 429) {
        return new Response(
          JSON.stringify({ error: 'Rate limit exceeded. Please try again in a moment.' }),
          { status: 429, headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
        );
      }
      if (response.status === 402) {
        return new Response(
          JSON.stringify({ error: 'AI credits exhausted. Please add credits to continue.' }),
          { status: 402, headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
        );
      }
      const errorText = await response.text();
      console.error('AI Gateway error:', response.status, errorText);
      throw new Error(`AI Gateway error: ${response.status}`);
    }

    const data = await response.json();
    const content = data.choices?.[0]?.message?.content;
    
    if (!content) {
      throw new Error('No response from AI');
    }

    console.log('AI response:', content);

    // Parse the JSON response
    let workflowData;
    try {
      // Extract JSON from markdown code blocks if present
      let jsonStr = content.trim();
      
      // Remove markdown code blocks if present
      const codeBlockMatch = jsonStr.match(/```(?:json)?\s*([\s\S]*?)\s*```/);
      if (codeBlockMatch) {
        jsonStr = codeBlockMatch[1].trim();
      }
      
      // If no code block, try to find JSON object
      if (!jsonStr.startsWith('{') && !jsonStr.startsWith('[')) {
        const jsonMatch = jsonStr.match(/(\{[\s\S]*\}|\[[\s\S]*\])/);
        if (jsonMatch) {
          jsonStr = jsonMatch[1];
        }
      }
      
      // Check if the response looks truncated
      if (!jsonStr.endsWith('}') && !jsonStr.endsWith(']')) {
        console.warn('Response appears truncated, attempting to parse anyway');
      }
      
      workflowData = JSON.parse(jsonStr);
      console.log('Successfully parsed workflow from image(s)');
      
      // If AI returned multiple workflows in a workflows array, validate each has nodes
      if (workflowData.workflows && Array.isArray(workflowData.workflows)) {
        console.log(`Detected ${workflowData.workflows.length} workflows from AI response`);
        workflowData.workflows = workflowData.workflows.map((workflow: any, index: number) => {
          if (!workflow.nodes || !Array.isArray(workflow.nodes)) {
            console.warn(`Workflow ${index} missing nodes array, attempting to fix`);
            // If workflow has no nodes but has other data, try to extract nodes
            workflow.nodes = [];
          }
          
          // Inject guardrails for each workflow
          if (workflow.nodes.length > 0) {
            const injectionResult = injectGuardrailNodes(workflow.nodes);
            workflow.nodes = injectionResult.nodes;
            workflow.guardrailExplanations = injectionResult.explanations;
            workflow.complianceStandards = injectionResult.complianceStandards;
            workflow.guardrailsAdded = injectionResult.guardrailsAdded;
            console.log(`Guardrails injected for workflow ${index}:`, injectionResult.guardrailsAdded);
          }
          
          return workflow;
        });
      } else {
        // Single workflow - inject guardrails
        if (workflowData.nodes) {
          const injectionResult = injectGuardrailNodes(workflowData.nodes);
          workflowData.nodes = injectionResult.nodes;
          workflowData.guardrailExplanations = injectionResult.explanations;
          workflowData.complianceStandards = injectionResult.complianceStandards;
          workflowData.guardrailsAdded = injectionResult.guardrailsAdded;
          console.log('Guardrail nodes injected from image analysis:', injectionResult.guardrailsAdded);
        }
      }
    } catch (parseError) {
      console.error('Failed to parse AI response as JSON:', parseError);
      console.error('Content preview:', content.substring(0, 500));
      throw new Error('AI returned invalid JSON format. Please try again.');
    }

    return new Response(
      JSON.stringify(workflowData),
      { headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
    );

    } catch (aiError) {
      clearTimeout(timeoutId);
      if (aiError instanceof Error && aiError.name === 'AbortError') {
        console.error('AI request timed out');
        return new Response(
          JSON.stringify({ error: 'Request timed out. Please try with a smaller image.' }),
          { status: 504, headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
        );
      }
      throw aiError;
    }

  } catch (error) {
    console.error('Error in analyze-workflow-image:', error);
    console.error('Error stack:', error instanceof Error ? error.stack : 'No stack');
    return new Response(
      JSON.stringify({ 
        error: error instanceof Error ? error.message : 'Unknown error',
        details: error instanceof Error ? error.stack : undefined
      }),
      { status: 500, headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
    );
  }
});
